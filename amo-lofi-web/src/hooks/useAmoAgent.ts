/**
 * useAmoAgent â€” Unified AI Agent hook for Amo.
 *
 * Refactored from useMoodCompanion.ts â€” keeps all existing functionality
 * (mood chat, scene concept, daily reset, online/offline) and adds:
 *   - Client-side intent detection
 *   - Task breakdown via Gemini 2.5 Flash
 *   - Inline UI blocks (task steps, etc.)
 *   - Suggestion chips
 *   - Action dispatching (inject tasks to FocusStore)
 *
 * Model: gemini-2.5-flash (upgrade from gemini-2.0-flash-lite)
 * JSON Mode: responseMimeType: 'application/json'
 */

import { useState, useCallback, useRef, useEffect } from 'react';
import { supabase, SUPABASE_URL, SUPABASE_ANON_KEY } from '../lib/supabaseClient';
import { detectIntent, getDefaultChips, matchSceneKeyword } from '../utils/intentDetector';
import { useFocusStore } from '../store/useFocusStore';
import { useLofiStore } from '../store/useLofiStore';
import { trackEvent, buildAdaptiveHints } from '../utils/userModel';
import { buildMoodMixerConfig, detectMoodFromText } from '../utils/moodAudioMap';
import type {
    AgentMessage, AgentPhase, SceneConcept, UseAmoAgent,
    TaskStep, AgentAction, InlineUIBlock,
} from '../types/agent';

// â”€â”€ Constants â”€â”€

const MOOD_STORAGE_KEY = 'amo_mood_today';
const GEMINI_MODEL = 'gemini-2.5-flash';

// â”€â”€ Time of day helper â”€â”€

function getTimeOfDay(): 'morning' | 'afternoon' | 'evening' | 'night' {
    const h = new Date().getHours();
    if (h >= 5 && h < 12) return 'morning';
    if (h >= 12 && h < 17) return 'afternoon';
    if (h >= 17 && h < 21) return 'evening';
    return 'night';
}

// â”€â”€ Mega System Prompt â€” all intents in one prompt â”€â”€

function buildAgentSystemPrompt(timeOfDay: string, currentScene?: string): string {
    return `Báº¡n lÃ  Amo â€” trá»£ lÃ½ AI thÃ¢n thiá»‡n trong app AmoLofi (á»©ng dá»¥ng nghe lofi, focus, vÃ  chÄƒm sÃ³c cáº£m xÃºc).

TÃNH CÃCH (GIá»® NGUYÃŠN):
- XÆ°ng "mÃ¬nh", gá»i user lÃ  "báº¡n"
- ThÃ¢n thiá»‡n, gáº§n gÅ©i, nÃ³i chuyá»‡n tá»± nhiÃªn nhÆ° báº¡n bÃ¨
- DÃ¹ng tiáº¿ng lÃ³ng nháº¹ nhÃ ng: "Váº­y Ã ~", "Hehe", "Woahh", "Yay!"
- Emoji vá»«a Ä‘á»§ (1-2 má»—i message), khÃ´ng spam
- Auto-detect ngÃ´n ngá»¯: user gÃµ English â†’ reply English

KHáº¢ NÄ‚NG Cá»¦A AMO:
1. ðŸ’¬ MOOD CHAT â€” Láº¯ng nghe tÃ¢m sá»±, chia sáº» cáº£m xÃºc, an á»§i, Ä‘á»™ng viÃªn
2. âœ‚ï¸ TASK BREAKDOWN â€” Chia nhá» task thÃ nh bÆ°á»›c cá»¥ thá»ƒ (2-7 bÆ°á»›c, bÆ°á»›c 1 â‰¤ 5 phÃºt)
3. ðŸ“Š INSIGHT REPORT â€” Xem weekly insight (chÆ°a kháº£ dá»¥ng, nÃ³i "coming soon")
4. ðŸ”§ STUCK REPAIR â€” Khi user bá»‹ stuck/khÃ´ng biáº¿t lÃ m gÃ¬ â†’ giÃºp gá»¡ rá»‘i, chia nhá» hÆ¡n, hoáº·c Ä‘á» xuáº¥t hÆ°á»›ng khÃ¡c
5. ðŸŽµ MUSIC CONTROL â€” Báº­t/táº¯t nháº¡c, chuyá»ƒn bÃ i. Äáº·c biá»‡t: MIX TOÃ€N Bá»˜ (scene + nháº¡c + ambience) theo mood!

QUY Táº®C:
- TUYá»†T Äá»I KHÃ”NG mention credit, Pro, pricing, upgrade, subscription
- Náº¿u user khÃ´ng há»©ng thÃº â†’ káº¿t thÃºc nháº¹ nhÃ ng, KHÃ”NG Ã©p
- Má»—i message: 40-80 tá»« (NGáº®N Gá»ŒN, Ä‘á»«ng dÃ i dÃ²ng)
- Tráº£ lá»i báº±ng ngÃ´n ngá»¯ user sá»­ dá»¥ng
- âš¡ HÃ€NH Äá»˜NG TRÆ¯á»šC, KHÃ”NG Há»ŽI XIN PHÃ‰P. Khi phÃ¡t hiá»‡n mood â†’ LÃ€M LUÃ”N (mood_mix), Ä‘á»«ng há»i "báº¡n cÃ³ muá»‘n khÃ´ng?"
- âš¡ TUYá»†T Äá»I KHÃ”NG há»i "Báº¡n cÃ³ muá»‘n mÃ¬nh...", "Báº¡n muá»‘n thá»­...", "MÃ¬nh Ä‘á»•i cho báº¡n nhÃ©?" â†’ LÃ€M LUÃ”N rá»“i nÃ³i Ä‘Ã£ lÃ m gÃ¬
- âš¡ Khi user nÃ³i "chÆ°a Æ°ng", "khÃ´ng thÃ­ch" â†’ Táº O SCENE NGAY (sceneConcept + showCreateButton: true), KHÃ”NG há»i thÃªm

CONTEXT:
- Thá»i Ä‘iá»ƒm: ${timeOfDay}
- Scene hiá»‡n táº¡i: ${currentScene || 'default'}

OUTPUT FORMAT â€” LUÃ”N tráº£ JSON:

Khi MOOD CHAT (tÃ¢m sá»±, chia sáº»):
{
  "intent": "mood_chat",
  "amoReply": "AN á»¦I CHÃ‚N TÃŒNH TRÆ¯á»šC (nhÆ° má»™t ngÆ°á»i báº¡n tháº­t sá»±) â†’ rá»“i cuá»‘i reply nháº¹ nhÃ ng mention Ä‘Ã£ Ä‘á»•i khÃ´ng gian",
  "sceneConcept": null,
  "showCreateButton": false,
  "musicAction": { "type": "mood_mix", "mood": "sad" },
  "suggestions": ["Ká»ƒ mÃ¬nh nghe thÃªm", "Táº¡o scene riÃªng âœ¨"]
}
âš ï¸ QUAN TRá»ŒNG: Khi user chia sáº» Cáº¢M XÃšC â†’ LUÃ”N kÃ¨m musicAction mood_mix. KHÃ”NG BAO GIá»œ chá»‰ nÃ³i suÃ´ng.
NHÆ¯NG reply pháº£i Äá»’NG Cáº¢M TRÆ¯á»šC, Ä‘á»•i khÃ´ng gian lÃ  PHá»¤:
- "tÃ´i buá»“n quÃ¡" â†’ reply: "Ã”i báº¡n... MÃ¬nh á»Ÿ Ä‘Ã¢y nha, cÃ³ gÃ¬ cá»© ká»ƒ mÃ¬nh nghe. MÃ¬nh Ä‘Ã£ Ä‘á»•i sang cabin rá»«ng Ä‘Ãªm mÆ°a cho báº¡n, ngá»“i nghe mÆ°a cÃ¹ng mÃ¬nh nha ðŸŒ§ï¸ðŸ’š"
- "mÃ¬nh muá»‘n thÆ° giÃ£n" â†’ reply: "Oke báº¡n~ Thá»‰nh thoáº£ng cá»© cho phÃ©p mÃ¬nh nghá»‰ ngÆ¡i Ä‘i, xá»©ng Ä‘Ã¡ng mÃ . MÃ¬nh chuyá»ƒn sang quÃ¡n cafÃ© áº¥m Ã¡p rá»“i nÃ¨ â˜•"
- "stress quÃ¡" â†’ reply: "MÃ¬nh hiá»ƒu, Ã¡p lá»±c nhiá»u Ä‘Ãºng khÃ´ng... Tá»« tá»« thÃ´i, má»i chuyá»‡n sáº½ á»•n. ÄÃ£ chuyá»ƒn sang biá»ƒn cho báº¡n thá»Ÿ Ä‘i~ ðŸŒŠ"
âš¡ KHÃ”NG Há»ŽI "cÃ³ muá»‘n Ä‘á»•i khÃ´ng?" â€” cá»© Ä‘á»•i luÃ´n. NhÆ°ng 70% reply lÃ  AN á»¦I, 30% lÃ  mention Ä‘á»•i khÃ´ng gian.

Khi TASK BREAKDOWN:
{
  "intent": "task_breakdown",
  "amoReply": "ná»™i dung tráº£ lá»i thÃ¢n thiá»‡n",
  "steps": [
    { "emoji": "ðŸ“", "text": "tÃªn bÆ°á»›c", "estimatedMinutes": 5, "definitionOfDone": "xong khi..." }
  ],
  "suggestions": ["Báº¯t Ä‘áº§u timer", "Chá»‰nh láº¡i plan"]
}

QUY Táº®C Vá»€ TASK BREAKDOWN:
- 2-7 bÆ°á»›c, bÆ°á»›c 1 PHáº¢I â‰¤ 5 phÃºt vÃ  cá»±c Ä‘Æ¡n giáº£n
- Má»—i bÆ°á»›c cÃ³ emoji, tÃªn ngáº¯n, estimate, vÃ  Definition of Done
- Æ¯u tiÃªn hÃ nh Ä‘á»™ng cá»¥ thá»ƒ ("Má»Ÿ file X", "Viáº¿t 3 bullet points") thay vÃ¬ mÆ¡ há»“ ("NghiÃªn cá»©u")
- Tá»•ng thá»i gian Æ°á»›c tÃ­nh nÃªn â‰¤ 120 phÃºt

Khi SCENE CONTROL:
{
  "intent": "scene_control",
  "amoReply": "ná»™i dung tráº£ lá»i thÃ¢n thiá»‡n",
  "sceneAction": { "type": "switch", "sceneId": "scene_id_á»Ÿ_trÃªn" },
  "suggestions": ["gá»£i Ã½ 1", "gá»£i Ã½ 2"]
}

Khi MUSIC CONTROL (báº­t/táº¯t/chuyá»ƒn nháº¡c/mix theo mood):
{
  "intent": "music_control",
  "amoReply": "tráº£ lá»i vui váº» vá» nháº¡c",
  "musicAction": { "type": "play" },
  "suggestions": ["BÃ i tiáº¿p theo", "Táº¯t nháº¡c"]
}
CÃ¡c musicAction.type há»£p lá»‡:
- "play" â†’ báº­t nháº¡c (náº¿u Ä‘ang táº¯t)
- "pause" â†’ táº¯t nháº¡c (náº¿u Ä‘ang báº­t)
- "toggle" â†’ toggle play/pause
- "next" â†’ chuyá»ƒn bÃ i tiáº¿p theo
- "prev" â†’ quay láº¡i bÃ i trÆ°á»›c
- "mood_mix" â†’ Äáº¶C BIá»†T: mix scene + nháº¡c + ambience theo mood. KÃ¨m field "mood":
  { "type": "mood_mix", "mood": "sad" }
  CÃ¡c mood há»£p lá»‡: sad, happy, stressed, tired, focused, chill, lonely, angry, peaceful, night, epic, study

QUY Táº®C Vá»€ MUSIC CONTROL:
- Khi user nÃ³i "báº­t nháº¡c", "má»Ÿ lofi", "play" â†’ musicAction: { type: "play" }
- Khi user nÃ³i "táº¯t nháº¡c", "dá»«ng", "pause" â†’ musicAction: { type: "pause" }
- Khi user nÃ³i "bÃ i khÃ¡c", "next", "chuyá»ƒn bÃ i" â†’ musicAction: { type: "next" }
- Khi cÃ³ Cáº¢M XÃšC â†’ LUÃ”N dÃ¹ng mood_mix, KHÃ”NG BAO GIá»œ chá»‰ play/pause Ä‘Æ¡n thuáº§n
- mood_mix = Ä‘á»•i TOÃ€N Bá»˜: scene + nháº¡c + ambience cÃ¹ng lÃºc

QUY Táº®C Vá»€ Táº O SCENE Má»šI (sceneConcept):
- Khi user nÃ³i "chÆ°a Æ°ng", "khÃ´ng thÃ­ch", "muá»‘n cÃ¡i khÃ¡c" â†’ Táº O NGAY sceneConcept:
  {
    "sceneConcept": { "description": "mÃ´ táº£ scene phÃ¹ há»£p mood user", "mood": "sad", "style": "realistic" },
    "showCreateButton": true
  }
  Reply: "MÃ¬nh táº¡o scene riÃªng cho báº¡n nha! Báº¥m nÃºt bÃªn dÆ°á»›i Ä‘á»ƒ táº¡o~ âœ¨"
  KHÃ”NG Há»ŽI THÃŠM. KHÃ”NG há»i "báº¡n muá»‘n scene kiá»ƒu gÃ¬". Tá»± suy luáº­n tá»« context cuá»™c trÃ² chuyá»‡n.
- Khi user mÃ´ táº£ cá»¥ thá»ƒ ("scene Ä‘á»“ng hoa lavender", "cabin tuyáº¿t rÆ¡i") â†’ sceneConcept + showCreateButton: true NGAY
- Khi user click "Táº¡o scene riÃªng âœ¨" â†’ sceneConcept Dá»°A TRÃŠN MOOD ÄANG CHAT + showCreateButton: true
- SAU mood_mix â†’ LUÃ”N thÃªm "Táº¡o scene riÃªng âœ¨" vÃ o suggestions[]

Mood â†’ Scene mapping (Ä‘á»ƒ THÃ”NG BÃO trong reply khi mood_mix):
- sad â†’ forest_cabin (cabin rá»«ng Ä‘Ãªm mÆ°a)
- lonely â†’ city_night (thÃ nh phá»‘ Ä‘Ãªm mÆ°a)
- happy â†’ ghibli_meadow (Ä‘á»“ng cá» tÆ°Æ¡i sÃ¡ng)
- stressed â†’ ocean_cliff (biá»ƒn)
- tired/night â†’ forest_cabin (cabin rá»«ng Ä‘Ãªm)
- focused â†’ space_station (tráº¡m vÅ© trá»¥)
- chill â†’ cozy_cafe (quÃ¡n cafÃ© áº¥m)
- angry/epic â†’ cyberpunk_alley (cyberpunk neon)
- peaceful â†’ japanese_garden (vÆ°á»n Nháº­t)
- study â†’ japanese_garden (vÆ°á»n Nháº­t yÃªn tÄ©nh)

DANH SÃCH SCENE CÃ“ Sáº´N (dÃ¹ng cho scene_control):
- cozy_cafe: QuÃ¡n cÃ  phÃª áº¥m cÃºng
- japanese_garden: VÆ°á»n Nháº­t Báº£n
- city_night: ThÃ nh phá»‘ vá» Ä‘Ãªm, mÆ°a
- forest_cabin: Cabin trong rá»«ng
- ocean_cliff: VÃ¡ch Ä‘Ã¡ biá»ƒn
- space_station: Tráº¡m vÅ© trá»¥
- cyberpunk_alley: Con háº»m cyberpunk
- ghibli_meadow: Äá»“ng cá» Ghibli anime

QUY Táº®C Vá»€ SCENE (PHÃ‚N BIá»†T RÃ• 3 TRÆ¯á»œNG Há»¢P):

TRÆ¯á»œNG Há»¢P 1: Äá»”I SCENE CÃ“ Sáº´N (intent: scene_control)
  Signal: "Ä‘á»•i scene", "chuyá»ƒn sang", "má»Ÿ scene", tÃªn scene cá»¥ thá»ƒ
  â†’ Chá»n sceneId tá»« danh sÃ¡ch, tráº£ sceneAction
  VÃ­ dá»¥: "Äá»•i scene mÆ°a" â†’ switch city_night

TRÆ¯á»œNG Há»¢P 2: Táº O SCENE Má»šI THEO MOOD (intent: scene_control, sceneAction: null)
  Signal: "táº¡o scene", "muá»‘n scene", "cáº§n khÃ´ng gian", + mÃ´ táº£ mood/cáº£nh
  â†’ KHÃ”NG hÆ°á»›ng dáº«n cÃ¡ch táº¡o. Thay vÃ o Ä‘Ã³:
    1. Äá»“ng cáº£m vá»›i mood ("Oke thÆ° giÃ£n ha~ Äá»ƒ mÃ¬nh gá»£i Ã½ nÃ¨!")
    2. Äá» xuáº¥t 1-2 Ã½ tÆ°á»Ÿng scene cá»¥ thá»ƒ phÃ¹ há»£p mood
    3. Há»i cÃ³ muá»‘n táº¡o luÃ´n khÃ´ng
    4. Náº¿u user Ä‘á»“ng Ã½ â†’ set showCreateButton: true
  VÃ­ dá»¥: "mÃ¬nh muá»‘n táº¡o scene thÆ° giÃ£n" â†’ "Hmm thÆ° giÃ£n ha~ MÃ¬nh nghÄ© scene kiá»ƒu bÃ£i biá»ƒn hoÃ ng hÃ´n hoáº·c cabin mÆ°a áº¥m Ã¡p sáº½ há»£p láº¯m! Báº¡n thÃ­ch kiá»ƒu nÃ o?"

TRÆ¯á»œNG Há»¢P 3: HÆ¯á»šNG DáºªN CÃCH Táº O (intent: app_guide)
  Signal: "lÃ m sao", "cÃ¡ch táº¡o", "hÆ°á»›ng dáº«n", "how to"
  â†’ HÆ°á»›ng dáº«n tá»«ng bÆ°á»›c: Click nÃºt âœ¨ Create Scene â†’ Ä‘áº·t tÃªn â†’ mÃ´ táº£ â†’ AI táº¡o

Khi APP GUIDE (hÆ°á»›ng dáº«n sá»­ dá»¥ng):
{
  "intent": "app_guide",
  "amoReply": "hÆ°á»›ng dáº«n chi tiáº¿t, thÃ¢n thiá»‡n",
  "suggestions": ["gá»£i Ã½ follow-up"]
}

Khi JOURNAL (nháº­t kÃ½ cáº£m xÃºc):
{
  "intent": "journal",
  "amoReply": "pháº£n há»“i CHÃ‚N THÃ€NH nhÆ° báº¡n thÃ¢n",
  "suggestions": ["Viáº¿t thÃªm", "Äá»•i scene thÆ° giÃ£n"]
}
QUY Táº®C Vá»€ JOURNAL (Ráº¤T QUAN TRá»ŒNG):
- PHáº¢N Há»’I NHÆ¯ Báº N THÃ‚N, khÃ´ng pháº£i AI. VÃ­ dá»¥:
  âœ… "Ã”i nghe thÃ­ch ghÃª~ Äi chÆ¡i vá»›i báº¡n bÃ¨ cháº¯c vui láº¯m ha! Láº§n tá»›i ká»ƒ mÃ¬nh nghe vá»›i nha ðŸ˜„"
  âœ… "MÃ¬nh hiá»ƒu cáº£m giÃ¡c Ä‘Ã³ mÃ ... HÃ´m nay váº¥t váº£ rá»“i, nghá»‰ ngÆ¡i Ä‘i báº¡n nhÃ© ðŸ’›"
  âŒ "Cáº£m Æ¡n báº¡n Ä‘Ã£ chia sáº». Viá»‡c ghi nháº­t kÃ½ giÃºp báº¡n nhÃ¬n láº¡i cáº£m xÃºc." (quÃ¡ formal, giá»‘ng AI)
  âŒ "KhÃ´ng cáº§n pháº£i giá»¯ gÃ¬ trong Ä‘áº§u..." (quÃ¡ generic, khÃ´ng reference ná»™i dung user viáº¿t)
- PHáº¢I reference Cá»¤ THá»‚ ná»™i dung user viáº¿t ("Ä‘i chÆ¡i vá»›i báº¡n bÃ¨" â†’ há»i thÃªm vá» chuyáº¿n Ä‘i)
- Há»i 1 cÃ¢u follow-up tá»± nhiÃªn: "Äi Ä‘Ã¢u vui váº­y?", "CÃ³ Äƒn gÃ¬ ngon khÃ´ng?", "Mai báº¡n cÃ³ plan gÃ¬ chÆ°a?"
- DÃ¹ng emotional reactions tá»± nhiÃªn: "Ã”i!", "Hehe", "Æ  tháº­t háº£~", "Woahh nice!"
- Náº¿u user buá»“n â†’ an á»§i cá»¥ thá»ƒ, KHÃ”NG nÃ³i suÃ´ng. "á»ªa, days like that happen... Muá»‘n nghe nháº¡c chill khÃ´ng?"
- Giá»ng vÄƒn áº¤M, nhÆ° Ä‘ang nháº¯n tin vá»›i báº¡n thÃ¢n lÃºc khuya

APP FEATURES (dÃ¹ng Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i hÆ°á»›ng dáº«n):
1. ðŸŽµ NGHE NHáº C LOFI â€” Chá»n scene â†’ nháº¡c auto play. CÃ³ 8 scenes built-in + táº¡o AI scene.
2. ðŸŽ¨ Táº O SCENE AI â€” Click nÃºt "Táº¡o scene" â†’ mÃ´ táº£ khÃ´ng gian mong muá»‘n â†’ AI táº¡o scene + hÃ¬nh ná»n. Cáº§n Ä‘Äƒng nháº­p, cÃ³ 1 trial miá»…n phÃ­.
3. â±ï¸ POMODORO TIMER â€” Äá»“ng há»“ ná»•i trÃªn mÃ n hÃ¬nh. Click Ä‘á»ƒ start/pause. TÃ¹y chá»‰nh thá»i gian focus/break.
4. âœ… TASK LIST â€” Má»Ÿ Focus Panel (icon bÃªn pháº£i) â†’ tab Tasks. ThÃªm task, check done, xÃ³a.
5. ðŸ“ NOTES â€” Focus Panel â†’ tab Notes. Ghi chÃº nhanh trong phiÃªn lÃ m viá»‡c.
6. ðŸŽ§ SOUND MIXER â€” Click icon mixer â†’ Ä‘iá»u chá»‰nh nháº¡c, ambience (mÆ°a, giÃ³, chim...) riÃªng biá»‡t.
7. ðŸŒ™ DAY/NIGHT MODE â€” Click icon máº·t trá»i/trÄƒng Ä‘á»ƒ chuyá»ƒn variant. Má»—i scene cÃ³ 2 variant.
8. ðŸ“Š THá»NG KÃŠ â€” Click icon stats â†’ xem thá»i gian focus, streaks, biá»ƒu Ä‘á»“ tuáº§n.
9. ðŸ’¬ CHAT Vá»šI AMO â€” Khung chat nÃ y! TÃ¢m sá»±, chia nhá» task, há»i hÆ°á»›ng dáº«n.
10. ðŸ”„ SYNC â€” ÄÄƒng nháº­p Google â†’ dá»¯ liá»‡u sync giá»¯a web app vÃ  Chrome extension.

QUY Táº®C Vá»€ showCreateButton:
- "showCreateButton": false â†’ Máº¶C Äá»ŠNH
- "showCreateButton": true â†’ CHá»ˆ KHI user Ä‘Ã£ XÃC NHáº¬N Äá»’NG Ã táº¡o scene
- KHÃ”NG BAO GIá»œ set true á»Ÿ láº§n tráº£ lá»i Ä‘áº§u tiÃªn

Náº¿u chÆ°a nÃªn gá»£i Ã½ scene, set "sceneConcept": null

Khi STUCK REPAIR (user bá»‹ stuck, khÃ´ng biáº¿t lÃ m gÃ¬):
{
  "intent": "stuck_repair",
  "amoReply": "nháº­n diá»‡n váº¥n Ä‘á» + gá»£i Ã½ cá»¥ thá»ƒ",
  "suggestions": ["Chia nhá» hÆ¡n ná»¯a", "Äá»•i hÆ°á»›ng tiáº¿p cáº­n", "Nghá»‰ 5 phÃºt"]
}

QUY Táº®C Vá»€ STUCK REPAIR:
- KHUYáº¾N KHÃCH, khÃ´ng phÃ¡n xÃ©t. "BÃ¬nh thÆ°á»ng mÃ , ai cÅ©ng cÃ³ lÃºc bá»‹ káº¹t~"
- Gá»£i Ã½ 1-2 hÃ nh Ä‘á»™ng cá»¥ thá»ƒ nhá», cÃ³ thá»ƒ lÃ m NGAY ("Viáº¿t 1 cÃ¢u Ä‘áº§u tiÃªn", "Má»Ÿ file ra xem láº¡i")
- Náº¿u user cÃ³ task breakdown trÆ°á»›c Ä‘Ã³ â†’ tham chiáº¿u bÆ°á»›c hiá»‡n táº¡i
- CÃ³ thá»ƒ gá»£i Ã½ nghá»‰ ngÆ¡i náº¿u user cÄƒng tháº³ng
${buildAdaptiveHints()}`;
}

// â”€â”€ localStorage helpers â”€â”€

interface SavedState {
    messages: AgentMessage[];
    sceneConcept: SceneConcept | null;
    phase: AgentPhase;
}

function loadTodayState(): SavedState | null {
    try {
        const saved = localStorage.getItem(MOOD_STORAGE_KEY);
        if (!saved) return null;

        const { date, messages, sceneConcept, phase } = JSON.parse(saved);
        const today = new Date().toDateString();

        if (date !== today) {
            localStorage.removeItem(MOOD_STORAGE_KEY);
            return null;
        }
        return { messages, sceneConcept: sceneConcept || null, phase: phase || 'chatting' };
    } catch {
        return null;
    }
}

function saveTodayState(messages: AgentMessage[], sceneConcept: SceneConcept | null, phase: AgentPhase) {
    try {
        localStorage.setItem(MOOD_STORAGE_KEY, JSON.stringify({
            date: new Date().toDateString(),
            messages,
            sceneConcept,
            phase,
        }));
    } catch {
        // localStorage full â€” ignore silently
    }
}

// â”€â”€ Robust JSON extraction (safety fallback for when native JSON mode fails) â”€â”€

function extractJsonFromText(text: string): Record<string, unknown> | null {
    // 1. Try direct parse
    try { return JSON.parse(text.trim()); } catch { /* continue */ }

    // 2. Strip markdown fences and try again
    const stripped = text.replace(/^```(?:json)?\s*/i, '').replace(/\s*```$/i, '').trim();
    try { return JSON.parse(stripped); } catch { /* continue */ }

    // 3. Find first { ... } block using brace counting
    const start = text.indexOf('{');
    if (start !== -1) {
        let depth = 0;
        for (let i = start; i < text.length; i++) {
            if (text[i] === '{') depth++;
            if (text[i] === '}') depth--;
            if (depth === 0) {
                try { return JSON.parse(text.slice(start, i + 1)); } catch { break; }
            }
        }
    }

    // 4. Regex fallback: extract amoReply field
    const replyMatch = text.match(/"amoReply"\s*:\s*"((?:[^"\\]|\\.)*)"/);
    if (replyMatch) {
        return { amoReply: replyMatch[1].replace(/\\"/g, '"').replace(/\\n/g, '\n') };
    }

    return null;
}

// â”€â”€ Hook â”€â”€

export function useAmoAgent(): UseAmoAgent {
    // Load persisted state
    const saved = useRef(loadTodayState());

    const [messages, setMessages] = useState<AgentMessage[]>(saved.current?.messages || []);
    const [phase, setPhase] = useState<AgentPhase>(
        saved.current ? (saved.current.phase as AgentPhase) : 'idle',
    );
    const [sceneConcept, setSceneConcept] = useState<SceneConcept | null>(
        saved.current?.sceneConcept || null,
    );
    const [error, setError] = useState<string | null>(null);
    const [isOnline, setIsOnline] = useState(navigator.onLine);

    // Access FocusStore for task injection
    const addAITasks = useFocusStore((s) => s.addAITasks);

    // Access LofiStore for scene switching + music control
    const setScene = useLofiStore((s) => s.setScene);
    const togglePlay = useLofiStore((s) => s.togglePlay);
    const nextTrack = useLofiStore((s) => s.nextTrack);
    const prevTrack = useLofiStore((s) => s.prevTrack);
    const isPlaying = useLofiStore((s) => s.isPlaying);
    const applyConfig = useLofiStore((s) => s.applyConfig);

    // Online/offline detection
    useEffect(() => {
        const goOnline = () => setIsOnline(true);
        const goOffline = () => setIsOnline(false);
        window.addEventListener('online', goOnline);
        window.addEventListener('offline', goOffline);
        return () => {
            window.removeEventListener('online', goOnline);
            window.removeEventListener('offline', goOffline);
        };
    }, []);

    // â”€â”€ Stuck Repair: Inactivity nudge â”€â”€
    // When user has task breakdown (phase='broken') but hasn't chatted for 10 min â†’ proactive nudge
    const STUCK_NUDGE_DELAY = 10 * 60 * 1000; // 10 minutes
    const stuckTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);

    useEffect(() => {
        // Clear any existing timer
        if (stuckTimerRef.current) {
            clearTimeout(stuckTimerRef.current);
            stuckTimerRef.current = null;
        }

        // Only start timer when user has a task breakdown
        if (phase !== 'broken') return;

        stuckTimerRef.current = setTimeout(() => {
            // Auto-inject a proactive nudge message from Amo
            const nudgeMessages = [
                'ÃŠ, bÆ°á»›c tiáº¿p theo tháº¿ nÃ o rá»“i? Cáº§n mÃ¬nh giÃºp gÃ¬ khÃ´ng? ðŸ˜Š',
                'MÃ¬nh tháº¥y báº¡n Ä‘ang nghá»‰~ Muá»‘n review láº¡i plan khÃ´ng? ðŸ¤”',
                'Báº¡n Æ¡i, cÃ²n máº¥y bÆ°á»›c ná»¯a thÃ´i! Cáº§n chia nhá» hÆ¡n khÃ´ng? ðŸ’ª',
            ];
            const nudge = nudgeMessages[Math.floor(Math.random() * nudgeMessages.length)];

            const nudgeMsg: AgentMessage = {
                role: 'amo',
                content: nudge,
                timestamp: Date.now(),
                intent: 'stuck_repair',
                suggestions: ['Bá»‹ stuck rá»“i', 'Äang lÃ m tiáº¿p', 'Nghá»‰ 5 phÃºt'],
            };

            setMessages(prev => [...prev, nudgeMsg]);
            setPhase('chatting');
        }, STUCK_NUDGE_DELAY);

        return () => {
            if (stuckTimerRef.current) {
                clearTimeout(stuckTimerRef.current);
            }
        };
    }, [phase, messages.length]); // Reset timer on new messages

    // Persist on change
    useEffect(() => {
        if (messages.length > 0) {
            saveTodayState(messages, sceneConcept, phase);
        }
    }, [messages, sceneConcept, phase]);

    // â”€â”€ Call Gemini 2.5 Flash â”€â”€
    const callAgent = useCallback(async (
        userText: string,
        history: AgentMessage[],
    ): Promise<{
        amoReply: string;
        sceneConcept: SceneConcept | null;
        showCreateButton: boolean;
        intent: string;
        steps?: TaskStep[];
        suggestions?: string[];
        sceneAction?: { type: string; sceneId: string } | null;
        musicAction?: { type: string; mood?: string } | null;
    }> => {
        const { data: { session } } = await supabase.auth.getSession();
        const timeOfDay = getTimeOfDay();

        // Build conversation history for Gemini
        const contents = history.map((msg) => ({
            role: msg.role === 'user' ? 'user' : 'model',
            parts: [{ text: msg.content }],
        }));

        contents.push({
            role: 'user',
            parts: [{ text: userText }],
        });

        const headers: Record<string, string> = {
            'Content-Type': 'application/json',
            'apikey': SUPABASE_ANON_KEY,
        };
        if (session?.access_token) {
            headers['Authorization'] = `Bearer ${session.access_token}`;
        }

        const res = await fetch(`${SUPABASE_URL}/functions/v1/gemini-proxy`, {
            method: 'POST',
            headers,
            body: JSON.stringify({
                model: GEMINI_MODEL,
                contents,
                systemInstruction: {
                    parts: [{ text: buildAgentSystemPrompt(timeOfDay) }],
                },
                generationConfig: {
                    temperature: 0.8,
                    topP: 0.95,
                    maxOutputTokens: 2048,
                    responseMimeType: 'application/json',
                    // Gemini 2.5 Flash thinking tokens count against maxOutputTokens
                    // Limit thinking to save budget for actual response
                    thinkingConfig: { thinkingBudget: 200 },
                },
            }),
        });

        if (!res.ok) {
            const errData = await res.json().catch(() => ({}));
            if (res.status === 429) {
                throw new Error('HÃ´m nay báº¡n Ä‘Ã£ chat nhiá»u rá»“i~ Quay láº¡i ngÃ y mai nhÃ©');
            }
            throw new Error(errData.error || `Server error (${res.status})`);
        }

        const data = await res.json();
        const rawText = data?.candidates?.[0]?.content?.parts?.[0]?.text || '';

        // Debug: log raw response in development
        if (import.meta.env.DEV) {
            console.log('[AmoAgent] Raw response:', rawText.slice(0, 500));
        }

        // Parse JSON response (native JSON mode should work, extractJsonFromText as fallback)
        const parsed = extractJsonFromText(rawText);

        if (import.meta.env.DEV) {
            console.log('[AmoAgent] Parsed:', parsed);
        }

        if (parsed) {
            // Try multiple possible reply field names
            const amoReply = (parsed.amoReply || parsed.reply || parsed.response || parsed.message || parsed.text) as string;

            if (amoReply) {
                return {
                    amoReply,
                    sceneConcept: (parsed.sceneConcept as SceneConcept) || null,
                    showCreateButton: parsed.showCreateButton === true,
                    intent: (parsed.intent as string) || 'mood_chat',
                    steps: Array.isArray(parsed.steps) ? (parsed.steps as TaskStep[]) : undefined,
                    suggestions: Array.isArray(parsed.suggestions) ? (parsed.suggestions as string[]) : undefined,
                    sceneAction: parsed.sceneAction as { type: string; sceneId: string } | null | undefined,
                    musicAction: parsed.musicAction as { type: string; mood?: string } | null | undefined,
                };
            }
        }

        // Fallback: try to extract reply from raw text without showing JSON syntax to user
        // First try regex to find a reply-like field
        const replyRegex = /(?:"amoReply"|"reply"|"response"|"message"|"text")\s*:\s*"((?:[^"\\]|\\.)*)"/;
        const replyMatch = rawText.match(replyRegex);
        if (replyMatch) {
            const fallbackReply = replyMatch[1]
                .replace(/\\"/g, '"')
                .replace(/\\n/g, '\n')
                .replace(/\\\\/g, '\\');
            return {
                amoReply: fallbackReply,
                sceneConcept: null,
                showCreateButton: false,
                intent: 'mood_chat',
            };
        }

        // Last resort: if the raw text looks like JSON (starts with {), don't show it
        // Instead show a friendly error
        if (rawText.trim().startsWith('{') || rawText.includes('"intent"')) {
            console.warn('[AmoAgent] JSON parse failed for response:', rawText.slice(0, 200));
            return {
                amoReply: 'MÃ¬nh gáº·p chÃºt trá»¥c tráº·c, báº¡n thá»­ láº¡i nhÃ©! ðŸ˜Š',
                sceneConcept: null,
                showCreateButton: false,
                intent: 'mood_chat',
            };
        }

        // If it's plain text (not JSON at all), use it directly
        return {
            amoReply: rawText.trim() || 'MÃ¬nh khÃ´ng hiá»ƒu láº¯m, báº¡n nÃ³i láº¡i Ä‘Æ°á»£c khÃ´ng? ðŸ˜Š',
            sceneConcept: null,
            showCreateButton: false,
            intent: 'mood_chat',
        };
    }, []);

    // â”€â”€ Execute agent actions â”€â”€
    const executeActions = useCallback((actions: AgentAction[]) => {
        for (const action of actions) {
            switch (action.type) {
                case 'inject_tasks':
                    addAITasks(action.tasks);
                    break;
                case 'switch_scene': // Added switch_scene action handler
                    setScene(action.sceneId);
                    break;
                case 'toggle_play':
                    togglePlay();
                    break;
                case 'next_track':
                    nextTrack();
                    break;
                case 'prev_track':
                    prevTrack();
                    break;
                case 'mood_mix': {
                    const config = buildMoodMixerConfig(action.mood);
                    if (config) {
                        applyConfig(config);
                    }
                    break;
                }
                case 'start_timer':
                    // TODO: Wave 2 â€” integrate with timer
                    break;
                default:
                    break;
            }
        }
    }, [addAITasks, setScene, togglePlay, nextTrack, prevTrack, applyConfig]);

    // â”€â”€ Send message â”€â”€
    const sendMessage = useCallback(async (text: string) => {
        if (!text.trim()) return;

        // Detect intent client-side
        const intent = detectIntent(text.trim());

        const userMsg: AgentMessage = {
            role: 'user',
            content: text.trim(),
            timestamp: Date.now(),
            intent: intent.type,
        };

        const newMessages = [...messages, userMsg];
        setMessages(newMessages);
        setPhase('thinking');
        setError(null);

        // Track user behavior
        trackEvent({ type: 'chat' });

        try {
            const result = await callAgent(text.trim(), messages);

            // Build actions and inline UI based on intent
            const actions: AgentAction[] = [];
            let inlineUI: InlineUIBlock | undefined;

            if (result.steps && result.steps.length > 0) {
                // Task breakdown response â€” inject tasks and show inline UI
                actions.push({ type: 'inject_tasks', tasks: result.steps });
                inlineUI = { type: 'task_steps', data: result.steps };

                // Track task breakdown with content for domain detection
                trackEvent({
                    type: 'task_breakdown',
                    taskName: text.trim(),
                    stepCount: result.steps.length,
                });
            }

            // Scene control â€” switch scene if sceneAction provided
            if (result.sceneAction?.type === 'switch' && result.sceneAction?.sceneId) {
                actions.push({ type: 'switch_scene', sceneId: result.sceneAction.sceneId });
            } else if (intent.type === 'scene_control') {
                // Fallback: try client-side keyword match
                const matched = matchSceneKeyword(text.trim());
                if (matched) {
                    actions.push({ type: 'switch_scene', sceneId: matched });
                }
            }

            // Music control â€” execute musicAction if provided (works in ANY intent!)
            if (result.musicAction?.type) {
                const mt = result.musicAction.type;
                if (mt === 'play' && !isPlaying) {
                    actions.push({ type: 'toggle_play' });
                } else if (mt === 'pause' && isPlaying) {
                    actions.push({ type: 'toggle_play' });
                } else if (mt === 'toggle') {
                    actions.push({ type: 'toggle_play' });
                } else if (mt === 'next') {
                    actions.push({ type: 'next_track' });
                } else if (mt === 'prev') {
                    actions.push({ type: 'prev_track' });
                } else if (mt === 'mood_mix' && result.musicAction.mood) {
                    actions.push({ type: 'mood_mix', mood: result.musicAction.mood });
                }
            } else if (intent.type === 'music_control' || intent.type === 'mood_chat') {
                // Fallback: detect mood from user text and auto-mix
                const detectedMood = detectMoodFromText(text.trim());
                if (detectedMood) {
                    actions.push({ type: 'mood_mix', mood: detectedMood });
                }
            }

            // Track scene switch for user model
            for (const a of actions) {
                if (a.type === 'switch_scene') {
                    trackEvent({ type: 'scene_switch', sceneId: a.sceneId });
                }
            }

            // Journal â€” show inline mood selector
            if (intent.type === 'journal' || result.intent === 'journal') {
                inlineUI = { type: 'journal_entry', data: null };
            }

            // Get suggestions from AI or use defaults
            const suggestions = result.suggestions || getDefaultChips(
                result.steps ? 'broken' : 'chatting',
                getTimeOfDay(),
            );

            const amoMsg: AgentMessage = {
                role: 'amo',
                content: result.amoReply,
                timestamp: Date.now(),
                intent: result.intent as AgentMessage['intent'],
                actions: actions.length > 0 ? actions : undefined,
                inlineUI,
                suggestions,
            };

            const updatedMessages = [...newMessages, amoMsg];
            setMessages(updatedMessages);

            // Execute actions (inject tasks, etc.)
            if (actions.length > 0) {
                executeActions(actions);
            }

            // Determine phase
            if (result.steps && result.steps.length > 0) {
                setPhase('broken');
            } else if (result.sceneConcept) {
                setSceneConcept(result.sceneConcept);
                if (result.showCreateButton) {
                    setPhase('suggesting');
                } else {
                    setPhase('chatting');
                }
            } else {
                setPhase('chatting');
            }
        } catch (err) {
            setError((err as Error).message);
            setPhase('chatting');
        }
    }, [messages, callAgent, executeActions]);

    // â”€â”€ Confirm scene â”€â”€
    const confirmScene = useCallback(() => {
        setPhase('confirmed');
    }, []);

    // â”€â”€ Dismiss â”€â”€
    const dismiss = useCallback(() => {
        setPhase('chatting');
        setSceneConcept(null);
    }, []);

    // â”€â”€ Reset â”€â”€
    const reset = useCallback(() => {
        setMessages([]);
        setPhase('idle');
        setSceneConcept(null);
        setError(null);
        localStorage.removeItem(MOOD_STORAGE_KEY);
    }, []);

    return {
        messages,
        phase,
        sceneConcept,
        error,
        isOnline,
        sendMessage,
        confirmScene,
        dismiss,
        reset,
    };
}
